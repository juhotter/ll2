a.)


double factor = 1;

for (int i=0; i < n; i++) {
    x[i] = factor * y[i];
    factor = factor / 2;
}



Questions:
-Where are the data dependencies?
There are no Data dependencies in general. No loop carried and no "normal" ones.



-How can you parallelize the loops?
The appraoches i tried below. i made the factor private, so every single loop has its own copy.

-Implement the original and parallelized versions and compare their wall time for reasonable sizes and numbers of threads.
Wall Time for the serial Version: 10.1487 seconds.

For this version above i get 4.49 seconds. So theres a huge improvement.

#pragma omp parallel for private(factor)
for (int i = 0; i < n; i++)
{
    x[i] = factor * y[i];
    factor = factor / 2;
}


________________________________________________________________________________________________________________
b)

for (int i = 1; i<n; i++) {
    x[i] = (x[i] + y[i-1]) / 2;
    y[i] = y[i] + z[i] * 3;
}

Questions:
-Where are the data dependencies?
The data dependencies are between the X array and the Y array. There are loop carried dependencies.

-How can you parallelize the loops?
i tried the two appraoches above with time measured.

-Implement the original and parallelized versions and compare their wall time for reasonable sizes and numbers of threads.
Wall time with the same values for both measures
Serial: 12.1110 seconds
Parallel: first i tried to make two loops out of it. And now parallelize these with pragma parallel for. So i got  a wall time for 8.59 seconds.

Like this:
#pragma omp parallel for
for (int i = 1; i<n; i++) {
    y[i] = y[i] + z[i] * 3;
}

#pragma omp parallel for
for (int i = 1; i<n; i++) {
    x[i] = (x[i] + y[i-1]) / 2;
   
}

Then i made simply a PRAGMA OMP PARALLEL FOR without splitting the loop into two

#pragma omp parallel for
for (int i = 1; i<n; i++) {
    x[i] = (x[i] + y[i-1]) / 2;
    y[i] = y[i] + z[i] * 3;
}

This resultet in a time for 6.53 seconds.


Another simple approach would be to simply switch the two statements in the loop 

for (int i = 1; i<n; i++) {
     y[i] = y[i] + z[i] * 3;
    x[i] = (x[i] + y[i-1]) / 2;
   
}

So you have a true dependency, this does not parallelize per se, but brings an simple approvement and only needs 7.03 seconds now.


Resume: So the best one is Simply Using PRAGMA OMG PARALLEL FOR and leave the loop alltogether. But because there are a dependecy this can result in a error. So the safe
and best way to go is simply break the loops and parallelize it seperately.
________________________________________________________________________________________________________________

c)

x[0] = x[0] + 5 * y[0];
for (int i = 1; i<n; i++) {
    x[i] = x[i] + 5 * y[i];
    if ( twice ) {
        x[i-1] = 2 * x[i-1]
    }
}



Questions:
-Where are the data dependencies?
-How can you parallelize the loops?
-Implement the original and parallelized versions and compare their wall time for reasonable sizes and numbers of threads.
